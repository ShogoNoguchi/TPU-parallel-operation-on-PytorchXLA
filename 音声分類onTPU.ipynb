{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNlJ2RM0tcqf8Ml8ueOnWwC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShogoNoguchi/TPU-parallel-operation-on-PytorchXLA_Image-Multiclass-Classification/blob/main/%E9%9F%B3%E5%A3%B0%E5%88%86%E9%A1%9EonTPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMA4FdsQCYi3",
        "outputId": "254e8721-7953-43b2-915b-12d5611fba9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n",
            "Collecting tensorflow-cpu\n",
            "  Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.68.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow-cpu)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow-cpu)\n",
            "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.12.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-cpu)\n",
            "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (13.9.4)\n",
            "Collecting namex (from keras>=3.5.0->tensorflow-cpu)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.5.0->tensorflow-cpu)\n",
            "  Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
            "Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.3/381.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, optree, ml-dtypes, tensorboard, keras, tensorflow-cpu\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "Successfully installed keras-3.7.0 ml-dtypes-0.4.1 namex-0.0.8 optree-0.13.1 tensorboard-2.18.0 tensorflow-cpu-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch~=2.5.0 torch_xla[tpu]~=2.5.0 -f https://storage.googleapis.com/libtpu-releases/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-_DfoD1DWTR",
        "outputId": "a0004071-eefa-4b62-c424-e770ab047e51"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/libtpu-releases/index.html\n",
            "Requirement already satisfied: torch~=2.5.0 in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n",
            "Requirement already satisfied: torch_xla~=2.5.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]~=2.5.0) (2.5.1+libtpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch~=2.5.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.5.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.5.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.5.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.5.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.5.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch~=2.5.0) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla~=2.5.0->torch_xla[tpu]~=2.5.0) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_xla~=2.5.0->torch_xla[tpu]~=2.5.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch_xla~=2.5.0->torch_xla[tpu]~=2.5.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_xla~=2.5.0->torch_xla[tpu]~=2.5.0) (2.32.3)\n",
            "Requirement already satisfied: libtpu-nightly==0.1.dev20240916 in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]~=2.5.0) (0.1.dev20240916+nightly)\n",
            "Requirement already satisfied: tpu-info in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]~=2.5.0) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.5.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla~=2.5.0->torch_xla[tpu]~=2.5.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla~=2.5.0->torch_xla[tpu]~=2.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla~=2.5.0->torch_xla[tpu]~=2.5.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla~=2.5.0->torch_xla[tpu]~=2.5.0) (2024.8.30)\n",
            "Requirement already satisfied: grpcio>=1.65.5 in /usr/local/lib/python3.10/dist-packages (from tpu-info->torch_xla[tpu]~=2.5.0) (1.68.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from tpu-info->torch_xla[tpu]~=2.5.0) (4.25.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from tpu-info->torch_xla[tpu]~=2.5.0) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->tpu-info->torch_xla[tpu]~=2.5.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->tpu-info->torch_xla[tpu]~=2.5.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->tpu-info->torch_xla[tpu]~=2.5.0) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YshtPrUExDEO",
        "outputId": "d9ac51b5-bd0a-429c-8ad2-a334d95480b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Unsupported nprocs (8), ignoring...\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "エポック 1 訓練 - 平均損失: 1.5184, 精度: 62.30%\n",
            "エポック 1 検証 - 平均損失: 1.2598, 精度: 63.77%\n",
            "エポック 2 訓練 - 平均損失: 1.1109, 精度: 66.44%\n",
            "エポック 2 検証 - 平均損失: 0.9926, 精度: 69.12%\n",
            "エポック 3 訓練 - 平均損失: 0.8290, 精度: 73.39%\n",
            "エポック 3 検証 - 平均損失: 0.7607, 精度: 75.66%\n",
            "エポック 4 訓練 - 平均損失: 0.6904, 精度: 78.19%\n",
            "エポック 4 検証 - 平均損失: 0.6577, 精度: 78.97%\n",
            "エポック 5 訓練 - 平均損失: 0.5781, 精度: 81.13%\n",
            "エポック 5 検証 - 平均損失: 0.5774, 精度: 81.32%\n",
            "訓練完了！\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "def main(rank):\n",
        "    # デバイスの設定\n",
        "    device = xm.xla_device()\n",
        "\n",
        "    # データディレクトリの作成\n",
        "    data_dir = \"data\"\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    # ターゲットラベルの定義\n",
        "    target_labels = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
        "    unknown_label = 'unknown'\n",
        "    unique_labels = target_labels + [unknown_label]\n",
        "    label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "    # データセットクラスの定義\n",
        "    class SpeechCommandsDataset(Dataset):\n",
        "        def __init__(self, dataset, sample_rate=16000, n_mfcc=40, max_length=16000, label_map=None):\n",
        "            self.dataset = dataset\n",
        "            self.sample_rate = sample_rate\n",
        "            self.n_mfcc = n_mfcc\n",
        "            self.max_length = max_length\n",
        "            self.label_map = label_map\n",
        "\n",
        "            # 前処理トランスフォーム\n",
        "            self.resample_transform = torchaudio.transforms.Resample(orig_freq=16000, new_freq=sample_rate)\n",
        "            self.mfcc_transform = torchaudio.transforms.MFCC(\n",
        "                sample_rate=sample_rate,\n",
        "                n_mfcc=n_mfcc,\n",
        "                melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": n_mfcc},\n",
        "            )\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dataset)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            waveform, original_sample_rate, label, _, _ = self.dataset[idx]\n",
        "            label = label if label in target_labels else unknown_label\n",
        "            if original_sample_rate != self.sample_rate:\n",
        "                waveform = self.resample_transform(waveform)\n",
        "            waveform = (waveform - waveform.mean()) / waveform.std()\n",
        "            if waveform.size(1) < self.max_length:\n",
        "                padding = self.max_length - waveform.size(1)\n",
        "                waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
        "            else:\n",
        "                waveform = waveform[:, :self.max_length]\n",
        "            mfcc = self.mfcc_transform(waveform)\n",
        "            label_id = self.label_map[label] if self.label_map else label\n",
        "            return mfcc, label_id\n",
        "\n",
        "    # モデルクラスの定義\n",
        "    class SpeechCommandClassifier(nn.Module):\n",
        "        def __init__(self, n_mfcc=40, num_classes=len(label_map)):\n",
        "            super(SpeechCommandClassifier, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "            self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "            # フラット化後のサイズを計算\n",
        "            with torch.no_grad():\n",
        "                sample_input = torch.zeros(1, 1, n_mfcc, 101)\n",
        "                out = self.pool(F.relu(self.conv1(sample_input)))\n",
        "                out = self.pool(F.relu(self.conv2(out)))\n",
        "                flattened_size = out.view(-1).shape[0]\n",
        "\n",
        "            self.fc1 = nn.Linear(flattened_size, 128)\n",
        "            self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.pool(F.relu(self.conv1(x)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            x = x.view(x.size(0), -1)  # フラット化\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    # ランク0のみがデータをダウンロード\n",
        "    if rank == 0:\n",
        "        train_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_dir, subset='training', download=True)\n",
        "        validation_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_dir, subset='validation', download=True)\n",
        "        test_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_dir, subset='testing', download=True)\n",
        "    xm.rendezvous('download_complete')\n",
        "\n",
        "    # 他のプロセスはダウンロード済みのデータを使用\n",
        "    if rank != 0:\n",
        "        train_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_dir, subset='training', download=False)\n",
        "        validation_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_dir, subset='validation', download=False)\n",
        "        test_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_dir, subset='testing', download=False)\n",
        "\n",
        "    # データセットのインスタンスを作成\n",
        "    train_data = SpeechCommandsDataset(train_dataset, label_map=label_map)\n",
        "    validation_data = SpeechCommandsDataset(validation_dataset, label_map=label_map)\n",
        "\n",
        "    # バッチサイズの設定\n",
        "    batch_size = 64\n",
        "\n",
        "    # DistributedSampler を使用してデータを分散\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        train_data,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
        "    validation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # モデルの定義とデバイスへの移動\n",
        "    model = SpeechCommandClassifier(n_mfcc=40, num_classes=len(label_map)).to(device)\n",
        "\n",
        "    # 損失関数とオプティマイザーの定義\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # 訓練関数の定義\n",
        "    def train(epoch):\n",
        "        model.train()\n",
        "        train_sampler.set_epoch(epoch)\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for X, y in train_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "            total_loss += loss.item() * X.size(0)\n",
        "            total_correct += (pred.argmax(1) == y).sum().item()\n",
        "            total_samples += X.size(0)\n",
        "            # ステップのマーク\n",
        "            xm.mark_step()\n",
        "\n",
        "        avg_loss = total_loss / total_samples\n",
        "        accuracy = total_correct / total_samples * 100\n",
        "        if xm.is_master_ordinal():\n",
        "            print(f\"エポック {epoch} 訓練 - 平均損失: {avg_loss:.4f}, 精度: {accuracy:.2f}%\")\n",
        "\n",
        "    # 検証関数の定義\n",
        "    def validate(epoch):\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y in validation_loader:\n",
        "                X = X.to(device)\n",
        "                y = y.to(device)\n",
        "                pred = model(X)\n",
        "                loss = loss_fn(pred, y)\n",
        "                total_loss += loss.item() * X.size(0)\n",
        "                total_correct += (pred.argmax(1) == y).sum().item()\n",
        "                total_samples += X.size(0)\n",
        "                xm.mark_step()\n",
        "\n",
        "        avg_loss = total_loss / total_samples\n",
        "        accuracy = total_correct / total_samples * 100\n",
        "        if xm.is_master_ordinal():\n",
        "            print(f\"エポック {epoch} 検証 - 平均損失: {avg_loss:.4f}, 精度: {accuracy:.2f}%\")\n",
        "\n",
        "    # エポック数の設定\n",
        "    epochs = 5\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(epoch)\n",
        "        validate(epoch)\n",
        "\n",
        "    if xm.is_master_ordinal():\n",
        "        print(\"訓練完了！\")\n",
        "\n",
        "# xmp.spawn を使用して各 TPU コア上でプロセスを起動\n",
        "if __name__ == '__main__':\n",
        "    xmp.spawn(main, args=(), nprocs=8, start_method='fork')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHRMVkV66FbZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}